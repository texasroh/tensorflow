{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((5,5))\n",
    "a.reshape(5, 5, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# for conv2d input shape\n",
    "train_images = train_images[..., None] # (60000, 28, 28, 1)\n",
    "test_images = test_images[..., None] # (10000, 28, 28, 1)\n",
    "\n",
    "train_images = train_images / np.float32(255) # rescale\n",
    "test_images = test_images / np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of devices: 1\n"
     ]
    }
   ],
   "source": [
    "print('Num of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_images)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
    "    test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32,3,activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Conv2D(64,3, activation = 'relu'),\n",
    "        tf.keras.layers.MaxPooling2D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        reduction = tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size = GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    \n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "        name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    checkpoint = tf.train.Checkpoint(optimizer = optimizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def train_step(inputs):\n",
    "        images, labels = inputs\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images, training=True)\n",
    "            loss = compute_loss(labels, predictions)\n",
    "            \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        train_accuracy.update_state(labels, predictions)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(inputs):\n",
    "        images, labels = inputs\n",
    "        \n",
    "        predictions = model(images, training = False)\n",
    "        t_loss = loss_object(labels, predictions)\n",
    "        \n",
    "        test_loss.update_state(t_loss)\n",
    "        test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\workspace\\python\\jupyterenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "WARNING:tensorflow:From <ipython-input-14-852e9f1161d7>:4: StrategyBase.experimental_run_v2 (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "renamed to `run`\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1, Loss: 0.5057141184806824, Accuracy: 81.89833068847656, Test_Loss: 0.3793594241142273, Test_Accuracy: 86.43000030517578\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 2, Loss: 0.33520931005477905, Accuracy: 87.89666748046875, Test_Loss: 0.3423846662044525, Test_Accuracy: 87.52999877929688\n",
      "Epoch 3, Loss: 0.29017671942710876, Accuracy: 89.48500061035156, Test_Loss: 0.29893016815185547, Test_Accuracy: 89.16000366210938\n",
      "Epoch 4, Loss: 0.26124197244644165, Accuracy: 90.42833709716797, Test_Loss: 0.28242406249046326, Test_Accuracy: 89.83000183105469\n",
      "Epoch 5, Loss: 0.23345200717449188, Accuracy: 91.36833190917969, Test_Loss: 0.27660202980041504, Test_Accuracy: 89.70999908447266\n",
      "Epoch 6, Loss: 0.2142336219549179, Accuracy: 92.16667175292969, Test_Loss: 0.2657214403152466, Test_Accuracy: 90.12000274658203\n",
      "Epoch 7, Loss: 0.1996697336435318, Accuracy: 92.66166687011719, Test_Loss: 0.25752392411231995, Test_Accuracy: 91.00999450683594\n",
      "Epoch 8, Loss: 0.1838052123785019, Accuracy: 93.26000213623047, Test_Loss: 0.25081583857536316, Test_Accuracy: 90.97000122070312\n",
      "Epoch 9, Loss: 0.17050696909427643, Accuracy: 93.71666717529297, Test_Loss: 0.25772368907928467, Test_Accuracy: 90.58999633789062\n",
      "Epoch 10, Loss: 0.15638165175914764, Accuracy: 94.22167205810547, Test_Loss: 0.25655418634414673, Test_Accuracy: 90.90999603271484\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    @tf.function\n",
    "    def distributed_train_step(dataset_inputs):\n",
    "        per_replica_losses = strategy.experimental_run_v2(train_step, args=(dataset_inputs,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "    \n",
    "    @tf.function\n",
    "    def distributed_test_step(dataset_inputs):\n",
    "        return strategy.experimental_run_v2(test_step, args=(dataset_inputs,))\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for x in train_dist_dataset:\n",
    "            total_loss += distributed_train_step(x)\n",
    "            num_batches += 1\n",
    "        train_loss = total_loss / num_batches\n",
    "        \n",
    "        for x in test_dist_dataset:\n",
    "            distributed_test_step(x)\n",
    "            \n",
    "        if epoch % 2 ==0:\n",
    "            checkpoint.save(checkpoint_prefix)\n",
    "            \n",
    "        template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test_Loss: {}, Test_Accuracy: {}\")\n",
    "        print(template.format(epoch + 1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n",
    "        \n",
    "        test_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='eval_accuracy')\n",
    "\n",
    "new_model = create_model()\n",
    "new_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(images, labels):\n",
    "    predictions = new_model(images, training=False)\n",
    "    eval_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model not using strategy: 90.58999633789062\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(optimizer = new_optimizer, model = new_model)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    eval_step(images, labels)\n",
    "    \n",
    "print('Restored model not using strategy: {}'.format(eval_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.15883013606071472, Accuracy: 94.53125\n",
      "Epoch 10, Loss: 0.12042137235403061, Accuracy: 95.9375\n",
      "Epoch 10, Loss: 0.11272521317005157, Accuracy: 96.09375\n",
      "Epoch 10, Loss: 0.12551774084568024, Accuracy: 96.09375\n",
      "Epoch 10, Loss: 0.16023202240467072, Accuracy: 94.6875\n",
      "Epoch 10, Loss: 0.1287182867527008, Accuracy: 95.0\n",
      "Epoch 10, Loss: 0.12287051975727081, Accuracy: 95.3125\n",
      "Epoch 10, Loss: 0.11338094621896744, Accuracy: 95.15625\n",
      "Epoch 10, Loss: 0.13191018998622894, Accuracy: 94.53125\n",
      "Epoch 10, Loss: 0.11839397996664047, Accuracy: 94.84375\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    for _ in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        train_iter = iter(train_dist_dataset)\n",
    "        \n",
    "        for _ in range(10):\n",
    "            total_loss += distributed_train_step(next(train_iter))\n",
    "            num_batches += 1\n",
    "        average_train_loss = total_loss / num_batches\n",
    "        \n",
    "        template=(\"Epoch {}, Loss: {}, Accuracy: {}\")\n",
    "        print(template.format(epoch +1, average_train_loss, train_accuracy.result()*100))\n",
    "        train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, LOSS: 0.14341290295124054, Accuracy: 94.69000244140625\n",
      "Epoch 2, LOSS: 0.13122905790805817, Accuracy: 95.11833190917969\n",
      "Epoch 3, LOSS: 0.12313083559274673, Accuracy: 95.36332702636719\n",
      "Epoch 4, LOSS: 0.11050769686698914, Accuracy: 95.86499786376953\n",
      "Epoch 5, LOSS: 0.10170077532529831, Accuracy: 96.25333404541016\n",
      "Epoch 6, LOSS: 0.09410367161035538, Accuracy: 96.37667083740234\n",
      "Epoch 7, LOSS: 0.08666103333234787, Accuracy: 96.7366714477539\n",
      "Epoch 8, LOSS: 0.0795668363571167, Accuracy: 97.0\n",
      "Epoch 9, LOSS: 0.07453759014606476, Accuracy: 97.16999816894531\n",
      "Epoch 10, LOSS: 0.06742487847805023, Accuracy: 97.53166198730469\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    @tf.function\n",
    "    def distributed_train_epoch(dataset):\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for x in dataset:\n",
    "            per_replica_losses = strategy.experimental_run_v2(train_step, args=(x, ))\n",
    "            total_loss += strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "            num_batches += 1\n",
    "        return total_loss / tf.cast(num_batches, dtype=tf.float32)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss = distributed_train_epoch(train_dist_dataset)\n",
    "        \n",
    "        template = (\"Epoch {}, LOSS: {}, Accuracy: {}\")\n",
    "        print(template.format(epoch + 1, train_loss, train_accuracy.result()*100))\n",
    "        \n",
    "        train_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
