{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only allocate 1GB * 2 of memory on the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024 * 2)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Virtual devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npath_to_file = 'kor-eng/kor.txt'\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'''\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
    "'''\n",
    "path_to_file = 'kor-eng/kor.txt'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_csv(path_to_file, sep='\\t', header=None)[[0,1]].to_csv(path_to_file, sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    #w = unicode_to_ascii(w.lower().strip())\n",
    "    \n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", w)\n",
    "    \n",
    "    w = w.strip()\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> May I borrow this book ? <end>\n",
      "b'<start> \\xec\\x9d\\xb4 \\xec\\xb1\\x85 \\xec\\xa2\\x80 \\xeb\\xb9\\x8c\\xeb\\xa6\\xb4 \\xec\\x88\\x98 \\xec\\x9e\\x88\\xec\\x9d\\x84\\xea\\xb9\\x8c ? <end>'\n",
      "<start> 이 책 좀 빌릴 수 있을까 ? <end>\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "kor_sentence = u\"이 책 좀 빌릴 수 있을까?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(kor_sentence).encode('utf-8'))\n",
    "print(preprocess_sentence(kor_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')] for l in lines[:num_examples]]\n",
    "    \n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> If you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> Si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un m sico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "en, kor = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(kor[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples = None):\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print(\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "6 ----> ¿\n",
      "97 ----> ten\n",
      "13 ----> s\n",
      "1053 ----> dudas\n",
      "5 ----> ?\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "22 ----> do\n",
      "6 ----> you\n",
      "29 ----> have\n",
      "1117 ----> doubts\n",
      "7 ----> ?\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print()\n",
    "print(\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 18]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                      return_sequences=True,\n",
    "                                      return_state=True,\n",
    "                                      recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 18, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        #query hidden state shape == (batch_size, hidden size)\n",
    "        #query_with_time_axis_shape == (batch_size, 1, hidden size)\n",
    "        #values shape == (batch_size, max_len, hidden size)\n",
    "        #we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "        #score shape == (batch_size, max_length, 1)\n",
    "        #we get 1 at the last axis because we are applying score to self.V\n",
    "        #the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "        \n",
    "        #attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        #context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                      return_sequences = True,\n",
    "                                      return_state = True,\n",
    "                                      recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        #used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        #enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        \n",
    "        #x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        #x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        #passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        #output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        #output shape == (batch+size, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4934)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_hidden, sample_output)\n",
    "\n",
    "print('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer = optimizer, \n",
    "                                encoder = encoder,\n",
    "                                decoder = decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Strategy\n",
    "<ol>\n",
    "    <li>Pass the input through the encoder which return encoder output and the encoder hidden state.</li>\n",
    "    <li>The encoder output, encoder hidden state and the decoder input (which is the start token) is passed to the decoder.</li>\n",
    "    <li>The decoder returns the predictions and the decoder hidden state.</li>\n",
    "    <li>The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.</li>\n",
    "    <li>Use teacher forcing to decide the next input to the decoder.</li>\n",
    "    <li>Teacher forcing is the technique where the target word is passed as the next input to the decoder.</li>\n",
    "    <li>The final step is to calculate the gradients and apply it to the optimizer and backpropagate.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']]*BATCH_SIZE, 1)\n",
    "        \n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            \n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            \n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6745\n",
      "Epoch 1 Batch 100 Loss 2.1961\n",
      "Epoch 1 Batch 200 Loss 2.0082\n",
      "Epoch 1 Batch 300 Loss 1.7722\n",
      "Epoch 1 Loss 2.0721\n",
      "Time taken for 1 epoch 93.32070255279541 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.6803\n",
      "Epoch 2 Batch 100 Loss 1.6360\n",
      "Epoch 2 Batch 200 Loss 1.5496\n",
      "Epoch 2 Batch 300 Loss 1.3447\n",
      "Epoch 2 Loss 1.4952\n",
      "Time taken for 1 epoch 72.6403112411499 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.2324\n",
      "Epoch 3 Batch 100 Loss 1.2286\n",
      "Epoch 3 Batch 200 Loss 1.1299\n",
      "Epoch 3 Batch 300 Loss 0.9894\n",
      "Epoch 3 Loss 1.1245\n",
      "Time taken for 1 epoch 70.88514614105225 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.8207\n",
      "Epoch 4 Batch 100 Loss 0.8613\n",
      "Epoch 4 Batch 200 Loss 0.7960\n",
      "Epoch 4 Batch 300 Loss 0.7725\n",
      "Epoch 4 Loss 0.8127\n",
      "Time taken for 1 epoch 72.18241596221924 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.6535\n",
      "Epoch 5 Batch 100 Loss 0.6005\n",
      "Epoch 5 Batch 200 Loss 0.5151\n",
      "Epoch 5 Batch 300 Loss 0.5545\n",
      "Epoch 5 Loss 0.5755\n",
      "Time taken for 1 epoch 59.512595891952515 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.3286\n",
      "Epoch 6 Batch 100 Loss 0.3862\n",
      "Epoch 6 Batch 200 Loss 0.4015\n",
      "Epoch 6 Batch 300 Loss 0.4598\n",
      "Epoch 6 Loss 0.4061\n",
      "Time taken for 1 epoch 62.33301854133606 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.2377\n",
      "Epoch 7 Batch 100 Loss 0.3371\n",
      "Epoch 7 Batch 200 Loss 0.2855\n",
      "Epoch 7 Batch 300 Loss 0.3346\n",
      "Epoch 7 Loss 0.2900\n",
      "Time taken for 1 epoch 63.32978963851929 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1974\n",
      "Epoch 8 Batch 100 Loss 0.1813\n",
      "Epoch 8 Batch 200 Loss 0.2141\n",
      "Epoch 8 Batch 300 Loss 0.2399\n",
      "Epoch 8 Loss 0.2133\n",
      "Time taken for 1 epoch 63.304176807403564 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1753\n",
      "Epoch 9 Batch 100 Loss 0.1610\n",
      "Epoch 9 Batch 200 Loss 0.1439\n",
      "Epoch 9 Batch 300 Loss 0.1951\n",
      "Epoch 9 Loss 0.1624\n",
      "Time taken for 1 epoch 63.31138610839844 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1277\n",
      "Epoch 10 Batch 100 Loss 0.1130\n",
      "Epoch 10 Batch 200 Loss 0.1129\n",
      "Epoch 10 Batch 300 Loss 0.1935\n",
      "Epoch 10 Loss 0.1284\n",
      "Time taken for 1 epoch 65.32359981536865 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate\n",
    "<ul>\n",
    "    <li>The evaluate function is similar to the training loop, except we don't use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.</li>\n",
    "    <li>Stop predicting when the model predicts the end token.</li>\n",
    "    <li>And store the attention weights for every time step.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                          maxlen = max_length_inp,\n",
    "                                                          padding = 'post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    \n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        \n",
    "        #storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "        \n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation = 90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict = fontdict)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x235a6d145c8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate(u'여기 매우 춥다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate(u'여기가 내 삶이야')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate(u'아직 집이니?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate(u'한번 시도해봐.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> esta es mi vida . <end>\n",
      "Predicted translation: this is my life . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\python\\jupyterenv\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n",
      "c:\\workspace\\python\\jupyterenv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'esta es mi vida.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> trata de averiguarlo . <end>\n",
      "Predicted translation: try to figure it out . <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\python\\jupyterenv\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n",
      "c:\\workspace\\python\\jupyterenv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 잘못된 번역\n",
    "translate(u'trata de averiguarlo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
