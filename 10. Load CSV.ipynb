{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked wieght</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell wieght</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked wieght  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell wieght  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names = ['Length', 'Diameter', 'Height', 'Whole weight', 'Shucked wieght', 'Viscera weight', 'Shell wieght', 'Age']\n",
    ")\n",
    "\n",
    "abalone_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_features = abalone_train.copy()\n",
    "abalone_labels = abalone_features.pop('Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.435, 0.335, 0.11 , ..., 0.136, 0.077, 0.097],\n",
       "       [0.585, 0.45 , 0.125, ..., 0.354, 0.207, 0.225],\n",
       "       [0.655, 0.51 , 0.16 , ..., 0.396, 0.282, 0.37 ],\n",
       "       ...,\n",
       "       [0.53 , 0.42 , 0.13 , ..., 0.374, 0.167, 0.249],\n",
       "       [0.395, 0.315, 0.105, ..., 0.118, 0.091, 0.119],\n",
       "       [0.45 , 0.355, 0.12 , ..., 0.115, 0.067, 0.16 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_features = np.array(abalone_features)\n",
    "abalone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone_model = tf.keras.Sequential([\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "\n",
    "abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 638us/step - loss: 87.3252\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 555us/step - loss: 16.3958\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 532us/step - loss: 9.2370\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 526us/step - loss: 8.2449\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 518us/step - loss: 7.7916\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 519us/step - loss: 7.5072\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 554us/step - loss: 6.9682\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 512us/step - loss: 7.0687\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 566us/step - loss: 6.7632\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 529us/step - loss: 6.5526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c4490d188>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize.adapt(abalone_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 0s 647us/step - loss: 102.0244\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 0s 522us/step - loss: 68.2818\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 0s 542us/step - loss: 24.8431\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 0s 538us/step - loss: 6.5281\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 0s 534us/step - loss: 4.9015\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 0s 504us/step - loss: 4.5869\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 0s 526us/step - loss: 5.0797\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 0s 570us/step - loss: 4.9427\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 0s 562us/step - loss: 4.7864\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 0s 534us/step - loss: 4.4566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c44a043c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_abalone_model = tf.keras.Sequential([\n",
    "    normalize,\n",
    "    layers.Dense(64),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "norm_abalone_model.compile(loss = tf.losses.MeanSquaredError(),\n",
    "                           optimizer = tf.optimizers.Adam())\n",
    "\n",
    "norm_abalone_model.fit(abalone_features, abalone_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Third</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
       "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
       "1         1  female  38.0                   1      0  71.2833  First        C   \n",
       "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
       "3         1  female  35.0                   1      0  53.1000  First        C   \n",
       "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
       "\n",
       "   embark_town alone  \n",
       "0  Southampton     n  \n",
       "1    Cherbourg     n  \n",
       "2  Southampton     y  \n",
       "3  Southampton     n  \n",
       "4   Queenstown     y  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features = titanic.copy()\n",
    "titanic_labels = titanic_features.pop('survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None,) dtype=float32 (created by layer 'tf.__operators__.add')>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tf.keras.Input(shape=(), dtype=tf.float32)\n",
    "\n",
    "result = 2*input + 1\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = tf.keras.Model(inputs=input, outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(calc(1).numpy())\n",
    "print(calc(2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'sex')>,\n",
       " 'age': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'age')>,\n",
       " 'n_siblings_spouses': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'n_siblings_spouses')>,\n",
       " 'parch': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'parch')>,\n",
       " 'fare': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'fare')>,\n",
       " 'class': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'class')>,\n",
       " 'deck': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'deck')>,\n",
       " 'embark_town': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'embark_town')>,\n",
       " 'alone': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'alone')>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {}\n",
    "\n",
    "for name, column in titanic_features.items():\n",
    "    dtype = column.dtype\n",
    "    if dtype == object:\n",
    "        dtype = tf.string\n",
    "    else:\n",
    "        dtype = tf.float32\n",
    "        \n",
    "    inputs[name] = tf.keras.Input(shape=(1, ), name=name, dtype=dtype)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'normalization_1')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = {name:input for name,input in inputs.items()\n",
    "                  if input.dtype==tf.float32}\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = preprocessing.Normalization()\n",
    "norm.adapt(np.array(titanic[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "all_numeric_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs = [all_numeric_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, input in inputs.items():\n",
    "    if input.dtype==tf.float32:\n",
    "        continue\n",
    "    lookup = preprocessing.StringLookup(vocabulary=np.unique(titanic_features[name]))\n",
    "    one_hot = preprocessing.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "    \n",
    "    x=lookup(input)\n",
    "    x = one_hot(x)\n",
    "    preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"dot\" with args ['-Tps', 'C:\\\\Users\\\\June\\\\AppData\\\\Local\\\\Temp\\\\tmphcrmtu8c'] returned code: 1\n",
      "\n",
      "stdout, stderr:\n",
      " b''\n",
      "b'Format: \"ps\" not recognized. Use one of:\\r\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e3d2ecd888c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpreprocessed_inputs_cat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtitanic_preprocessing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed_inputs_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitanic_preprocessing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"LR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m72\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\workspace\\python\\project1\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[0;32m    329\u001b[0m       \u001b[0mrankdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrankdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m       \u001b[0mexpand_nested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpand_nested\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m       dpi=dpi)\n\u001b[0m\u001b[0;32m    332\u001b[0m   \u001b[0mto_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\workspace\\python\\project1\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     message = (\n\u001b[0;32m    107\u001b[0m         \u001b[1;34m'Failed to import pydot. You must `pip install pydot` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\workspace\\python\\project1\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mcheck_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvocationException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\workspace\\python\\project1\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1943\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1945\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1947\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstdout_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "titanic_preprocessing = tf.keras.Model(inputs, preprocessed_inputs_cat)\n",
    "tf.keras.utils.plot_model(model = titanic_preprocessing, rankdir=\"LR\", dpi=72, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_features_dict = {name: np.array(value)\n",
    "                         for name, value in titanic_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 33), dtype=float32, numpy=\n",
       "array([[-0.61 ,  0.395, -0.479, -0.497,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  1.   ,  0.   ,\n",
       "         0.   ,  0.   ,  0.   ,  1.   ,  0.   ,  0.   ,  0.   ,  1.   ,\n",
       "         0.   ]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "titanic_preprocessing(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titanic_model(preprocessing_head, inputs):\n",
    "    body = tf.keras.Sequential([\n",
    "        layers.Dense(64),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    preprocessed_inputs = preprocessing_head(inputs)\n",
    "    result = body(preprocessed_inputs)\n",
    "    model = tf.keras.Model(inputs, result)\n",
    "    \n",
    "    model.compile(loss = tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  optimizer = tf.optimizers.Adam())\n",
    "    return model\n",
    "\n",
    "titanic_model = titanic_model(titanic_preprocessing, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.7498\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 0s 892us/step - loss: 0.5655\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 0s 840us/step - loss: 0.5281\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 0s 893us/step - loss: 0.4499\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 0s 840us/step - loss: 0.4430\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 0s 908us/step - loss: 0.4219\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 0s 892us/step - loss: 0.4057\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 0s 911us/step - loss: 0.4375\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 0s 854us/step - loss: 0.4000\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 0s 840us/step - loss: 0.4328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c4d325408>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(x=titanic_features_dict, y=titanic_labels, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: test\\assets\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x0000027C50980828> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "titanic_model.save('test')\n",
    "reloaded = tf.keras.models.load_model('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-1.872]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-1.872]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features_dict = {name:values[:1] for name, values in titanic_features_dict.items()}\n",
    "\n",
    "before = titanic_model(features_dict)\n",
    "after = reloaded(features_dict)\n",
    "assert (before-after)<1e-3\n",
    "print(before)\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def slices(features):\n",
    "    for i in itertools.count():\n",
    "        example = {name:values[i] for name,values in features.items()}\n",
    "        yield example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                : male\n",
      "age                : 22.0\n",
      "n_siblings_spouses : 1\n",
      "parch              : 0\n",
      "fare               : 7.25\n",
      "class              : Third\n",
      "deck               : unknown\n",
      "embark_town        : Southampton\n",
      "alone              : n\n"
     ]
    }
   ],
   "source": [
    "for example in slices(titanic_features_dict):\n",
    "    for name, value in example.items():\n",
    "        print(f\"{name:19s}: {value}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_ds = tf.data.Dataset.from_tensor_slices((titanic_features_dict, titanic_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_batches = titanic_ds.shuffle(len(titanic_labels)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4220\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4211\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4226\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4222\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27c4add8d88>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_model.fit(titanic_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tf-datasets/titanic/train.csv\n",
      "32768/30874 [===============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "titanic_file_path = tf.keras.utils.get_file('train.csv', 'https://storage.googleapis.com/tf-datasets/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_csv_ds = tf.data.experimental.make_csv_dataset(\n",
    "    titanic_file_path,\n",
    "    batch_size = 5,\n",
    "    label_name='survived',\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'female' b'male' b'male' b'female' b'male']\n",
      "age                 : [52. 46. 59. 25. 19.]\n",
      "n_siblings_spouses  : [1 1 0 1 0]\n",
      "parch               : [0 0 0 2 0]\n",
      "fare                : [ 78.267  61.175  13.5   151.55   10.5  ]\n",
      "class               : [b'First' b'First' b'Second' b'First' b'Second']\n",
      "deck                : [b'D' b'E' b'unknown' b'C' b'unknown']\n",
      "embark_town         : [b'Cherbourg' b'Southampton' b'Southampton' b'Southampton' b'Southampton']\n",
      "alone               : [b'n' b'n' b'y' b'n' b'y']\n",
      "\n",
      "label               : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for batch, label in titanic_csv_ds.take(1):\n",
    "    for key,value in batch.items():\n",
    "        print(f\"{key:20s}: {value}\")\n",
    "    print()\n",
    "    print(f\"{'label':20s}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_volume_csv_gz = tf.keras.utils.get_file(\n",
    "    'Metro_Interstate_Traffic_Volume.csv.gz',\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/00492/Metro_Interstate_Traffic_Volume.csv.gz\",\n",
    "    cache_dir='.', cache_subdir='traffic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holiday             : [b'None' b'None' b'None' b'None' b'None']\n",
      "temp                : [282.92 272.37 258.45 271.86 273.42]\n",
      "rain_1h             : [0.42 0.   0.   0.   0.  ]\n",
      "snow_1h             : [0. 0. 0. 0. 0.]\n",
      "clouds_all          : [92 90 20 90 40]\n",
      "weather_main        : [b'Rain' b'Clouds' b'Clouds' b'Mist' b'Clouds']\n",
      "weather_description : [b'heavy intensity rain' b'overcast clouds' b'few clouds' b'mist'\n",
      " b'scattered clouds']\n",
      "date_time           : [b'2013-10-15 17:00:00' b'2013-04-11 06:00:00' b'2013-01-13 22:00:00'\n",
      " b'2013-04-20 09:00:00' b'2013-04-21 23:00:00']\n",
      "\n",
      "label               : [6237 3973 1274 3745  960]\n"
     ]
    }
   ],
   "source": [
    "traffic_volume_csv_gz_ds = tf.data.experimental.make_csv_dataset(\n",
    "    traffic_volume_csv_gz,\n",
    "    batch_size=256,\n",
    "    label_name='traffic_volume',\n",
    "    num_epochs=1,\n",
    "    compression_type='GZIP'\n",
    ")\n",
    "\n",
    "for batch, label in traffic_volume_csv_gz_ds.take(1):\n",
    "    for key, value in batch.items():\n",
    "        print(f\"{key:20s}: {value[:5]}\")\n",
    "    print()\n",
    "    print(f\"{'label':20s}: {label[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 5.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, (batch, label) in enumerate(traffic_volume_csv_gz_ds.repeat(20)):\n",
    "    if i % 40 ==0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 914 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "caching = traffic_volume_csv_gz_ds.cache().shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(caching.shuffle(1000).repeat(20)):\n",
    "    if i % 40 ==0 :\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................................................................................\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "snapshot = tf.data.experimental.snapshot('titanic.tfsnap')\n",
    "snapshotting = traffic_volume_csv_gz_ds.apply(snapshot).shuffle(1000)\n",
    "\n",
    "for i, (batch, label) in enumerate(snapshotting.shuffle(1000).repeat(20)):\n",
    "    if i % 40 == 0:\n",
    "        print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\n",
      "160317440/160313983 [==============================] - 14s 0us/step\n"
     ]
    }
   ],
   "source": [
    "fonts_zip = tf.keras.utils.get_file(\n",
    "    'fonts.zip', \"https://archive.ics.uci.edu/ml/machine-learning-databases/00417/fonts.zip\",\n",
    "    cache_dir='.', cache_subdir='fonts',\n",
    "    extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fonts\\\\AGENCY.csv',\n",
       " 'fonts\\\\ARIAL.csv',\n",
       " 'fonts\\\\BAITI.csv',\n",
       " 'fonts\\\\BANKGOTHIC.csv',\n",
       " 'fonts\\\\BASKERVILLE.csv',\n",
       " 'fonts\\\\BAUHAUS.csv',\n",
       " 'fonts\\\\BELL.csv',\n",
       " 'fonts\\\\BERLIN.csv',\n",
       " 'fonts\\\\BERNARD.csv',\n",
       " 'fonts\\\\BITSTREAMVERA.csv']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "font_csvs = sorted(str(p) for p in pathlib.Path('fonts').glob(\"*.csv\"))\n",
    "\n",
    "font_csvs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(font_csvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = 'fonts/*.csv',\n",
    "    batch_size = 10, num_epochs=1,\n",
    "    num_parallel_reads=20,\n",
    "    shuffle_buffer_size = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font                : [b'COMMERCIALSCRIPT' b'FREESTYLE' b'NIRMALA' b'HARRINGTON' b'FORTE'\n",
      " b'FREESTYLE' b'BROADWAY' b'NIRMALA' b'BROADWAY' b'FORTE']\n",
      "fontVariant         : [b'COMMERCIALSCRIPT BT' b'FREESTYLE SCRIPT' b'NIRMALA UI SEMILIGHT'\n",
      " b'HARRINGTON' b'FORTE' b'FREESTYLE SCRIPT' b'BROADWAY'\n",
      " b'NIRMALA UI SEMILIGHT' b'BROADWAY' b'FORTE']\n",
      "m_label             : [ 190  235 3405  213  235  220  305 3455 8734  710]\n",
      "strength            : [0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]\n",
      "italic              : [0 1 0 0 1 0 0 0 1 0]\n",
      "orientation         : [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "m_top               : [47 42 24 25 32 21 45 27 45 32]\n",
      "m_left              : [20 19 23 23 24 21 24 23 25 29]\n",
      "originalH           : [31 32 65 59 47 56 36 66 29  9]\n",
      "originalW           : [48 35 35 39 44 43 16 77 51 20]\n",
      "h                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "w                   : [20 20 20 20 20 20 20 20 20 20]\n",
      "r0c0                : [  1   1   1   1   1   1 255   1   1   1]\n",
      "r0c1                : [  1   1   1   1   1   1 255   1   1   1]\n",
      "r0c2                : [  1   1   1   1   1   1 255   1   1   1]\n",
      "r0c3                : [ 23   1   1   1   1   1 255   1   1   1]\n",
      "...\n",
      "[total: 412 features]\n"
     ]
    }
   ],
   "source": [
    "for features in fonts_ds.take(1):\n",
    "    for i, (name, value) in enumerate(features.items()):\n",
    "        if i>15:\n",
    "            break\n",
    "        print(f\"{name:20s}: {value}\")\n",
    "print('...')\n",
    "print(f\"[total: {len(features)} features]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def make_images(features):\n",
    "    image=[None]*400\n",
    "    new_feats = {}\n",
    "    \n",
    "    for name, value in features.items():\n",
    "        match = re.match('r(\\d+)c(\\d+)', name)\n",
    "        if match:\n",
    "            image[int(match.group(1))*20 + int(match.group(2))] = value\n",
    "        else:\n",
    "            new_feats[name] = value\n",
    "            \n",
    "    image = tf.stack(image, axis=0)\n",
    "    image = tf.reshape(image, [20,20,-1])\n",
    "    new_feats['image'] = image\n",
    "    \n",
    "    return new_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_image_ds = fonts_ds.map(make_images)\n",
    "\n",
    "for features in fonts_image_ds.take(1):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6,6), dpi=120)\n",
    "\n",
    "for n in range(9):\n",
    "    plt.subplot(3,3,n+1)\n",
    "    plt.imshow(features['image'][..., n])\n",
    "    plt.title(chr(features['m_label'][n]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pathlib.Path(titanic_file_path).read_text()\n",
    "lines = text.split('\\n')[1:-1]\n",
    "\n",
    "all_strings = [str()]*10\n",
    "all_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n",
      "type: string, shape: (627,)\n"
     ]
    }
   ],
   "source": [
    "features = tf.io.decode_csv(lines, record_defaults = all_strings)\n",
    "\n",
    "for f in features:\n",
    "    print(f\"type: {f.dtype.name}, shape: {f.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, '', 0.0, 0, 0, 0.0, '', '', '', '']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_types = [int(), str(), float(), int(), int(), float(), str(), str(), str(), str()]\n",
    "titanic_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "simple_titanic = tf.data.experimental.CsvDataset(titanic_file_path, record_defaults=titanic_types, header=True)\n",
    "\n",
    "for example in simple_titanic.take(1):\n",
    "    print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, b'male', 22.0, 1, 0, 7.25, b'Third', b'unknown', b'Southampton', b'n']\n"
     ]
    }
   ],
   "source": [
    "def decode_titanic_line(line):\n",
    "    return tf.io.decode_csv(line, titanic_types)\n",
    "\n",
    "manual_titanic = (\n",
    "    tf.data.TextLineDataset(titanic_file_path)\n",
    "    .skip(1)\n",
    "    .map(decode_titanic_line)\n",
    ")\n",
    "\n",
    "for example in manual_titanic.take(1):\n",
    "    print([e.numpy() for e in example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGENCY,AGENCY FB,64258,0.400000,0,0.000000,35,21,51,22,20,20,1,1,1,21,101,210,255,255,255,255,255,255,255,255,255,255,255,255,255,255,1,1,1,93,255,255,255,176,146,146,146,146,146,146,146,146,216,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,141,141,141,182,255,255,255,172,141,141,141,115,1,1,1,1,163,255,255,255,255,255,255,255,255,255,255,255,255,255,255,209,1,1,1,1,163,255,255,255,6,6,6,96,255,255,255,74,6,6,6,5,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255,1,1,1,93,255,255,255,70,1,1,1,1,1,1,1,1,163,255,255,255\n"
     ]
    }
   ],
   "source": [
    "font_line = pathlib.Path(font_csvs[0]).read_text().splitlines()[1]\n",
    "print(font_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_font_features = font_line.count(',')+1\n",
    "font_column_types = [str(), str()] + [float()] * (num_font_features-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fonts\\\\AGENCY.csv'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "font_csvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_font_ds = tf.data.experimental.CsvDataset(\n",
    "    font_csvs,\n",
    "    record_defaults = font_column_types,\n",
    "    header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n",
      "b'AGENCY'\n"
     ]
    }
   ],
   "source": [
    "for row in simple_font_ds.take(10):\n",
    "    print(row[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_files = tf.data.Dataset.list_files('fonts/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "     b'fonts\\\\FELIX TITLING.csv'\n",
      "     b'fonts\\\\NIAGARA.csv'\n",
      "     b'fonts\\\\TAI.csv'\n",
      "     b'fonts\\\\ROMAN.csv'\n",
      "     b'fonts\\\\BITSTREAMVERA.csv'\n",
      "    ...\n",
      "\n",
      "Epoch 2:\n",
      "     b'fonts\\\\EBRIMA.csv'\n",
      "     b'fonts\\\\SWIS721.csv'\n",
      "     b'fonts\\\\QUICKTYPE.csv'\n",
      "     b'fonts\\\\BRITANNIC.csv'\n",
      "     b'fonts\\\\CENTAUR.csv'\n",
      "    ...\n"
     ]
    }
   ],
   "source": [
    "print('Epoch 1:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"    \", f.numpy())\n",
    "print('    ...')\n",
    "print()\n",
    "\n",
    "print('Epoch 2:')\n",
    "for f in list(font_files)[:5]:\n",
    "    print(\"    \", f.numpy())\n",
    "print('    ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_font_csv_ds(path):\n",
    "    return tf.data.experimental.CsvDataset(\n",
    "        path,\n",
    "        record_defaults=font_column_types,\n",
    "        header=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_rows = font_files.interleave(make_font_csv_ds, cycle_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>font_name</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STYLUS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KRISTEN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STYLUS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KRISTEN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>STYLUS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KRISTEN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MONEY</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  font_name character\n",
       "0     MONEY         2\n",
       "1    STYLUS         \n",
       "2   KRISTEN         \n",
       "3     MONEY         2\n",
       "4    STYLUS         \n",
       "5   KRISTEN         \n",
       "6     MONEY         0\n",
       "7    STYLUS         \n",
       "8   KRISTEN         \n",
       "9     MONEY         8"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fonts_dict = {'font_name':[], 'character': []}\n",
    "\n",
    "for row in font_rows.take(10):\n",
    "    fonts_dict['font_name'].append(row[0].numpy().decode())\n",
    "    fonts_dict['character'].append(chr(row[2].numpy()))\n",
    "    \n",
    "pd.DataFrame(fonts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "fonts_ds = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern = 'fonts/*.csv',\n",
    "    batch_size = BATCH_SIZE, num_epochs=1,\n",
    "    num_parallel_reads=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_ds.take(20)):\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_files = tf.data.Dataset.list_files('fonts/*.csv')\n",
    "fonts_lines = fonts_files.interleave(\n",
    "    lambda fname: tf.data.TextLineDataset(fname).skip(1),\n",
    "    cycle_length=100).batch(BATCH_SIZE)\n",
    "\n",
    "fonts_fast = fonts_lines.map(lambda x: tf.io.decode_csv(x, record_defaults=font_column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................\n",
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i,batch in enumerate(fonts_fast.take(20)):\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'n_siblings_spouses', 'parch', 'fare'])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "alone (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "class (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "deck (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embark_town (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fare (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "n_siblings_spouses (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "parch (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 33)           9           age[0][0]                        \n",
      "                                                                 alone[0][0]                      \n",
      "                                                                 class[0][0]                      \n",
      "                                                                 deck[0][0]                       \n",
      "                                                                 embark_town[0][0]                \n",
      "                                                                 fare[0][0]                       \n",
      "                                                                 n_siblings_spouses[0][0]         \n",
      "                                                                 parch[0][0]                      \n",
      "                                                                 sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 1)            2241        model_3[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,250\n",
      "Trainable params: 2,241\n",
      "Non-trainable params: 9\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "titanic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
